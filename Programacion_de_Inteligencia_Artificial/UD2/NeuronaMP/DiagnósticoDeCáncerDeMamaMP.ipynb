{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando la MP a un caso real :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI ML Breast Cancer Wisconsin\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar nuestro conjunto de datos\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X, columns = breast_cancer.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto entre train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de entrenamiento 426\n",
      "Tamaño de test 143\n"
     ]
    }
   ],
   "source": [
    "# Vamos a ver que conjunto de datos tenemos para train y test\n",
    "print(\"Tamaño de entrenamiento\", len(X_train))\n",
    "print(\"Tamaño de test\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar una neurona más avanzada\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MPNeuron:\n",
    "    def __init__(self) -> None:\n",
    "        self.threshold = None\n",
    "\n",
    "    def model(self, x):\n",
    "        z = sum(x)\n",
    "        return z >= self.threshold\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # input [[1,1,1,0], [1,0,1,1]]\n",
    "        Y = []\n",
    "        for x in X:\n",
    "            result = self.model(x)\n",
    "            Y.append(result)\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        accuracy = {}\n",
    "        # Seleccionar el threshold más óptimo entre todas las características de entrada\n",
    "        for th in range (X.shape[1]+1):\n",
    "            self.threshold = th\n",
    "            Y_pred = self.predict(X)\n",
    "            accuracy[th] = accuracy_score(Y_pred, Y)\n",
    "            print(accuracy[th])\n",
    "\n",
    "        # Vamos a seleccionaar el que mejor accuracy nos da\n",
    "        print(accuracy)\n",
    "        self.threshold = max(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 1, 0]\n",
      "Categories (2, int64): [0 < 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nuestra neurona MP solo acepta 0, 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(pd.cut([0.04, 0.3, 4, 5, 6, 7, 0.02], bins = 2, labels = [0,1]))\n",
    "\n",
    "plt.hist([0.04, 0.3, 4, 5, 6, 7, 0.02], bins = 2)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las características de entrada\n",
    "\n",
    "X_train_bin = X_train.apply(pd.cut, bins = 2, labels = [1, 0])\n",
    "X_test_bin = X_test.apply(pd.cut, bins = 2, labels = [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "120           1            1              1         1               1   \n",
       "384           1            1              1         1               1   \n",
       "438           1            1              1         1               1   \n",
       "467           1            1              1         1               1   \n",
       "256           0            0              0         1               1   \n",
       "..          ...          ...            ...       ...             ...   \n",
       "472           1            1              1         1               1   \n",
       "500           1            1              1         1               1   \n",
       "551           1            0              1         1               1   \n",
       "458           1            0              1         1               1   \n",
       "276           1            1              1         1               1   \n",
       "\n",
       "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "120                1              1                   1             1   \n",
       "384                1              1                   1             1   \n",
       "438                1              1                   1             1   \n",
       "467                1              1                   1             1   \n",
       "256                0              1                   0             1   \n",
       "..               ...            ...                 ...           ...   \n",
       "472                1              1                   1             1   \n",
       "500                1              1                   1             1   \n",
       "551                1              1                   1             1   \n",
       "458                1              1                   1             1   \n",
       "276                1              1                   1             1   \n",
       "\n",
       "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
       "120                      1  ...            1             1               1   \n",
       "384                      1  ...            1             1               1   \n",
       "438                      1  ...            1             1               1   \n",
       "467                      1  ...            1             1               1   \n",
       "256                      1  ...            0             0               0   \n",
       "..                     ...  ...          ...           ...             ...   \n",
       "472                      1  ...            1             1               1   \n",
       "500                      1  ...            1             1               1   \n",
       "551                      1  ...            1             1               1   \n",
       "458                      1  ...            1             0               1   \n",
       "276                      1  ...            1             1               1   \n",
       "\n",
       "    worst area worst smoothness worst compactness worst concavity  \\\n",
       "120          1                0                 1               1   \n",
       "384          1                1                 1               1   \n",
       "438          1                1                 1               1   \n",
       "467          1                1                 1               1   \n",
       "256          1                1                 0               1   \n",
       "..         ...              ...               ...             ...   \n",
       "472          1                1                 1               1   \n",
       "500          1                1                 1               1   \n",
       "551          1                1                 1               1   \n",
       "458          1                1                 1               1   \n",
       "276          1                1                 1               1   \n",
       "\n",
       "    worst concave points worst symmetry worst fractal dimension  \n",
       "120                    1              1                       1  \n",
       "384                    1              1                       1  \n",
       "438                    1              1                       1  \n",
       "467                    1              1                       1  \n",
       "256                    0              1                       1  \n",
       "..                   ...            ...                     ...  \n",
       "472                    1              1                       1  \n",
       "500                    1              1                       1  \n",
       "551                    1              1                       1  \n",
       "458                    1              1                       1  \n",
       "276                    1              1                       1  \n",
       "\n",
       "[426 rows x 30 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos nuestra Neurona\n",
    "\n",
    "mp_neuron = MPNeuron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6267605633802817\n",
      "0.6314553990610329\n",
      "0.6314553990610329\n",
      "0.636150234741784\n",
      "0.6408450704225352\n",
      "0.6502347417840375\n",
      "0.6596244131455399\n",
      "0.6666666666666666\n",
      "0.6713615023474179\n",
      "0.6995305164319249\n",
      "0.7300469483568075\n",
      "0.7652582159624414\n",
      "0.784037558685446\n",
      "0.8075117370892019\n",
      "0.8380281690140845\n",
      "0.852112676056338\n",
      "0.863849765258216\n",
      "0.8075117370892019\n",
      "0.7535211267605634\n",
      "{0: 0.6267605633802817, 1: 0.6267605633802817, 2: 0.6267605633802817, 3: 0.6267605633802817, 4: 0.6267605633802817, 5: 0.6267605633802817, 6: 0.6267605633802817, 7: 0.6267605633802817, 8: 0.6267605633802817, 9: 0.6267605633802817, 10: 0.6267605633802817, 11: 0.6267605633802817, 12: 0.6267605633802817, 13: 0.6314553990610329, 14: 0.6314553990610329, 15: 0.636150234741784, 16: 0.6408450704225352, 17: 0.6502347417840375, 18: 0.6596244131455399, 19: 0.6666666666666666, 20: 0.6713615023474179, 21: 0.6995305164319249, 22: 0.7300469483568075, 23: 0.7652582159624414, 24: 0.784037558685446, 25: 0.8075117370892019, 26: 0.8380281690140845, 27: 0.852112676056338, 28: 0.863849765258216, 29: 0.8075117370892019, 30: 0.7535211267605634}\n"
     ]
    }
   ],
   "source": [
    "# Encontrar ahora el threshold óptimo\n",
    "\n",
    "mp_neuron.fit(X_train_bin.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False, False, False,  True,  True,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a realizar la predicción de los ejemplos que no ha visto\n",
    "\n",
    "Y_pred = mp_neuron.predict(X_test_bin.to_numpy())\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred[0] # Me ha predicho que la primera del X_test es Falso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5664335664335665"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuanto de bien funciona nuestro modelo\n",
    "accuracy_score(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53,  0],\n",
       "       [62, 28]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Cómo obtengo ese accuracy?\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

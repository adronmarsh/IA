{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados con Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "\n",
    "# Ruta al ejecutable de ChromeDriver\n",
    "chrome_driver_path = r'C:\\Users\\Adri\\Downloads\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Configurar el servicio del controlador de Chrome\n",
    "chrome_service = ChromeService(executable_path=chrome_driver_path)\n",
    "\n",
    "# Configurar las opciones de Chrome en modo headless\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Habilitar el modo headless\n",
    "\n",
    "# Iniciar el navegador Chrome con las opciones de configuración\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options) \n",
    "\n",
    "# URLs de las páginas que deseas scrapear\n",
    "pages = ['https://www.jdsports.es/hombre/ropa-de-hombre/latest/',\n",
    "        'https://www.jdsports.es/hombre/calzado-de-hombre/zapatillas/'\n",
    "        ]\n",
    "\n",
    "for page in pages:\n",
    "    soup = BeautifulSoup(requests.get(page).content, 'html.parser')  # obtener el contenido de la página\n",
    "    product_items = soup.find_all(class_='productListItem')  # obtener todos los productos mediante la etiqueta html de productos\n",
    "\n",
    "    for product in product_items:\n",
    "        product_title = product.find(class_='itemTitle').find('a').text  # obtener el título de los productos\n",
    "        product_price = product.find(class_='itemPrice').find(class_='pri').text  # obtener el precio de los productos\n",
    "        product_link = \"https://www.jdsports.es\" + product.find(class_='itemTitle').find('a')['href']  # obtener el enlace de los productos\n",
    "\n",
    "        # Busca y muestra los colores disponibles\n",
    "        colors = []  # Lista de colores\n",
    "        try:\n",
    "            productSoup = BeautifulSoup(requests.get(product_link).content, 'html.parser')  # obtener el contenido de la página\n",
    "            color_list = productSoup.find('ul', class_='smScroll').find_all('li')\n",
    "            for color in color_list:\n",
    "                img = color.find('img')\n",
    "                if img:\n",
    "                    color_name = img['title']\n",
    "                    colors.append(color_name)\n",
    "        except Exception as e:\n",
    "            colors.append('Nan')  # Si no hay colores, agrega 'Nan' a la lista\n",
    "\n",
    "        driver.get(product_link)  # Abre la página de productos con Selenium\n",
    "\n",
    "        print(f\"º {product_title} | {product_price} | {product_link}\")\n",
    "\n",
    "        size_buttons = driver.find_elements(By.CSS_SELECTOR, 'button[data-e2e=\"pdp-productDetails-size\"]')\n",
    "        for size_button in size_buttons:\n",
    "            size = size_button.get_attribute('data-size')\n",
    "            price = size_button.get_attribute('data-price')\n",
    "            stock = size_button.get_attribute('data-stock')\n",
    "\n",
    "            # Si hay colores, formatea la cadena de colores\n",
    "            if colors:\n",
    "                if len(colors) > 1:\n",
    "                    color_string = ', '.join(colors[:-1]) + colors[-1] + '.'\n",
    "                else:\n",
    "                    color_string = colors[0] + '.'\n",
    "\n",
    "            print(f'Talla: {size} | Precio: {price} | Stock: {stock} | Colores: {color_string}')\n",
    "            \n",
    "driver.quit()  # Cierra el navegador al final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Función para mostrar un mensaje de carga\n",
    "def show_loading_message():\n",
    "    print(\"Cargando\", end=\"\")\n",
    "    for _ in range(3):\n",
    "        for _ in range(3):\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(1)\n",
    "        print(\" \", end=\"\", flush=True)\n",
    "\n",
    "# Archivo CSV para escribir los resultados\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "current_date_for_name = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "csv_file = open('productosJD' + current_date_for_name + \".csv\", 'w', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Título', 'Enlace', 'Colores', 'Precio', 'Moneda', 'Fecha'])\n",
    "\n",
    "# URLs de las páginas para scrapear\n",
    "pages = ['https://www.jdsports.es/hombre/ropa-de-hombre/latest/',\n",
    "         'https://www.jdsports.es/hombre/calzado-de-hombre/zapatillas/'\n",
    "        ]\n",
    "nurls = 0\n",
    "for page in pages:\n",
    "    show_loading_message()  # Muestra el mensaje de carga\n",
    "    soup = BeautifulSoup(requests.get(page).content, 'html.parser')  # obtener el contenido de la página\n",
    "    product_items = soup.find_all(class_='productListItem')  # obtener todos los productos mediante la etiqueta html de productos\n",
    "\n",
    "    for product in product_items:\n",
    "        product_title = product.find(class_='itemTitle').find('a').text  # obtener el título de los productos\n",
    "        product_price = product.find(class_='itemPrice').find(class_='pri').text  # obtener el precio de los productos\n",
    "        product_price = product_price.replace(\"€\", \"\")\n",
    "        product_price = product_price.replace(\",\", \".\")\n",
    "        product_link = \"https://www.jdsports.es\" + product.find(class_='itemTitle').find('a')['href']  # obtener el enlace de los productos\n",
    "\n",
    "        # Busca y muestra los colores disponibles\n",
    "        colors = []\n",
    "        try:\n",
    "            productSoup = BeautifulSoup(requests.get(product_link).content, 'html.parser')  # obtener el contenido de la página\n",
    "            color_list = productSoup.find('ul', class_='smScroll').find_all('li')\n",
    "            for color in color_list:\n",
    "                img = color.find('img')\n",
    "                if img:\n",
    "                    color_name = img['title']\n",
    "                    colors.append(color_name)\n",
    "        except Exception as e:\n",
    "            colors.append('Nan')  # Si no hay colores, agrega 'Nan' a la lista\n",
    "\n",
    "        # Si hay colores, formatea la cadena de colores\n",
    "        if colors:\n",
    "            if len(colors) > 1:\n",
    "                color_string = ', '.join(colors[:-1]) + colors[-1]\n",
    "            else:\n",
    "                color_string = colors[0]\n",
    "\n",
    "        # Escribe los resultados en el archivo CSV\n",
    "        csv_writer.writerow([product_title, product_link, color_string, product_price, \"€\", current_date])\n",
    "        nurls += 1\n",
    "    print(\"Listo\")  # Indica que se ha completado la carga de la página\n",
    "\n",
    "csv_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración de ChromeDriver para Selenium\n",
    "chrome_driver_path = r'C:\\Users\\Adri\\Downloads\\chromedriver-win64\\chromedriver.exe'\n",
    "chrome_service = ChromeService(executable_path=chrome_driver_path)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Archivo CSV para escribir los resultados\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "current_date_for_name = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "csv_file = open('productosJD' + current_date_for_name +\".csv\", 'w', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Título', 'Enlace', 'Talla', 'Stock', 'Colores', 'Precio', 'Moneda', 'Fecha'])\n",
    "\n",
    "# URLs de las páginas para scrapear\n",
    "pages = ['https://www.jdsports.es/hombre/ropa-de-hombre/latest/',\n",
    "         'https://www.jdsports.es/hombre/calzado-de-hombre/zapatillas/'\n",
    "        ]\n",
    "\n",
    "for page in pages:\n",
    "    soup = BeautifulSoup(requests.get(page).content, 'html.parser') # obtener el contenido de la página\n",
    "    product_items = soup.find_all(class_='productListItem') # obtener todos los productos mediante la etiqueta html de productos\n",
    "\n",
    "    for product in product_items:\n",
    "        product_title = product.find(class_='itemTitle').find('a').text # obtener el título de los productos\n",
    "        product_price = product.find(class_='itemPrice').find(class_='pri').text # obtener el precio de los productos\n",
    "        product_price = product_price.replace(\"€\", \"\")\n",
    "        product_price = product_price.replace(\",\", \".\")\n",
    "        product_link = \"https://www.jdsports.es\" + product.find(class_='itemTitle').find('a')['href']  # obtener el enlace de los productos\n",
    "\n",
    "        # Busca y muestra los colores disponibles\n",
    "        colors = []\n",
    "        try:\n",
    "            productSoup = BeautifulSoup(requests.get(product_link).content, 'html.parser') # obtener el contenido de la página\n",
    "            color_list = productSoup.find('ul', class_='smScroll').find_all('li')\n",
    "            for color in color_list:\n",
    "                img = color.find('img')\n",
    "                if img:\n",
    "                    color_name = img['title']\n",
    "                    colors.append(color_name)\n",
    "        except Exception as e:\n",
    "            colors.append('Nan') # Si no hay colores, agrega 'Nan' a la lista\n",
    "\n",
    "        driver.get(product_link) # Abre la página de productos con Selenium\n",
    "\n",
    "        size_buttons = driver.find_elements(By.CSS_SELECTOR, 'button[data-e2e=\"pdp-productDetails-size\"]')\n",
    "        for size_button in size_buttons:\n",
    "            size = size_button.get_attribute('data-size')\n",
    "            price = size_button.get_attribute('data-price')\n",
    "            stock = size_button.get_attribute('data-stock')\n",
    "\n",
    "            # Si hay colores, formatea la cadena de colores\n",
    "            if colors:\n",
    "                if len(colors) > 1:\n",
    "                    color_string = ', '.join(colors[:-1]) + colors[-1]\n",
    "                else:\n",
    "                    color_string = colors[0]\n",
    "\n",
    "            # Escribe los resultados en el archivo CSV\n",
    "            csv_writer.writerow([product_title, product_link, size, stock, color_string, product_price, \"€\", current_date])\n",
    "\n",
    "csv_file.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con el uso de Sitemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración de ChromeDriver para Selenium\n",
    "chrome_driver_path = r'C:\\Users\\Adri\\Downloads\\chromedriver-win64\\chromedriver.exe'\n",
    "chrome_service = ChromeService(executable_path=chrome_driver_path)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Crear CSV para exportar los resultados\n",
    "csv_file = open('productosJD.csv', 'w', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "csv_writer.writerow(['Título', 'Precio', 'Enlace', 'Talla', 'Precio Talla', 'Stock', 'Colores', 'Fecha'])\n",
    "\n",
    "# URL del sitemap\n",
    "sitemap_url = 'https://www.jdsports.es/sitemaps/es-es_desktop_categories_0.xml'\n",
    "\n",
    "# Obtener URLs del sitemap\n",
    "sitemap_response = requests.get(sitemap_url)\n",
    "sitemap_tree = ET.fromstring(sitemap_response.content)\n",
    "\n",
    "# Extraer URLs de las entradas del sitemap\n",
    "urls = [loc.text for loc in sitemap_tree.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}loc')]\n",
    "\n",
    "for page in urls:\n",
    "    soup = BeautifulSoup(requests.get(page).content, 'html.parser')  # obtener el contenido de la página\n",
    "    product_items = soup.find_all(class_='productListItem')  # obtener todos los productos mediante la etiqueta html de productos\n",
    "\n",
    "    for product in product_items:\n",
    "        product_title = product.find(class_='itemTitle').find('a').text  # obtener el título de los productos\n",
    "        product_price = product.find(class_='itemPrice').find(class_='pri').text  # obtener el precio de los productos\n",
    "        product_link = \"https://www.jdsports.es\" + product.find(class_='itemTitle').find('a')['href']  # obtener el enlace de los productos\n",
    "\n",
    "        # Busca y muestra los colores disponibles\n",
    "        colors = []\n",
    "        try:\n",
    "            productSoup = BeautifulSoup(requests.get(product_link).content, 'html.parser')  # obtener el contenido de la página\n",
    "            color_list = productSoup.find('ul', class_='smScroll').find_all('li')\n",
    "            for color in color_list:\n",
    "                img = color.find('img')\n",
    "                if img:\n",
    "                    color_name = img['title']\n",
    "                    colors.append(color_name)\n",
    "        except Exception as e:\n",
    "            colors.append('Nan')  # Si no hay colores, agrega 'Nan' a la lista\n",
    "\n",
    "        driver.get(product_link)  # Abre la página de productos con Selenium\n",
    "\n",
    "        size_buttons = driver.find_elements(By.CSS_SELECTOR, 'button[data-e2e=\"pdp-productDetails-size\"]')\n",
    "        for size_button in size_buttons:\n",
    "            size = size_button.get_attribute('data-size')\n",
    "            price = size_button.get_attribute('data-price')\n",
    "            stock = size_button.get_attribute('data-stock')\n",
    "\n",
    "            # Si hay colores, formatea la cadena de colores\n",
    "            if colors:\n",
    "                if len(colors) > 1:\n",
    "                    color_string = ', '.join(colors[:-1]) + colors[-1] + '.'\n",
    "                else:\n",
    "                    color_string = colors[0] + '.'\n",
    "\n",
    "            # Escribe los resultados en el archivo CSV\n",
    "            csv_writer.writerow([product_title, product_price, product_link, size, price, stock, color_string, current_date])\n",
    "\n",
    "csv_file.close()\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

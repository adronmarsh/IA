{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77954d6-8ef1-45ad-b18b-adf66aca6a6b",
   "metadata": {},
   "source": [
    "# Data Frames con pyspark\n",
    "\n",
    "ref: https://spark.apache.org/docs/3.1.1/api/python/getting_started/quickstart.html#DataFrame-Creation\n",
    "\n",
    "A la hora de crear data frames con spark tenemos varios mecanismos\n",
    "\n",
    "1) desde una lista de columnas sin esquema  (se infiere el esquema)\n",
    "2) desde una lista de columnas con esquema\n",
    "\n",
    "3) desde un data frame de pandas \n",
    "\n",
    "4) desde un RDD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e5cbe-a6b4-43bc-8c7a-4045c3b5ff29",
   "metadata": {},
   "source": [
    "## Método 1 desde una lista de columnas sin esquemas\n",
    "\n",
    "para ello se puede usar el método  \n",
    "spark.creeteDataFrame(  Array) que recibe como parámetro un array de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d808ac5-3410-4b1d-80ce-35f2865f39b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  4|5.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 f Creamos un data frame desde una lista de columnas  (sin espeficicar la estructura de datos \"esquema\" )\n",
    "from datetime import datetime, date\n",
    "#import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "print (df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40543664-57b0-4af8-ba3a-1b584c7d0ddf",
   "metadata": {},
   "source": [
    "## Método 2 desde una lista de columnas con esquema\n",
    "para ello se le pasa el esquema como segundo parámetro al metodo createDataFrame (Array , Schema)\n",
    "\n",
    "\n",
    "ejemplo:\n",
    "\n",
    "spark.createDataFrame(myArray, schema='a long, b double, c string, d date, e timestamp)\n",
    "\n",
    "## EJERCICIO 1 repetir la carga de los datos especificando el esquema de los datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf1c015-5fd3-4d6b-bc63-9527518a7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 desde una lista de columnas con esquema\n",
    "\n",
    "#Ejercicio 1: todo \n",
    "#repetir la carga de los datos especificando el esquema de los datos\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1906a1-86a8-4e90-997a-fbfda1d4467e",
   "metadata": {},
   "source": [
    "## Método 3 desde un DataFrame de Pandas \n",
    "\n",
    "Para ello partimos de un DataFrame creado con Pandas, es este ejemplo lo creamos el df manualmente. Una vez creado el data frame usamos la funcion createDataFrame(param1), que recibe como param 1 el data frame de pandas\n",
    "\n",
    "\n",
    "## Ejercicio 2 crear un dataframe desde un data frame de pandas, mostar los datos y la estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be7aec35-4774-41d5-95ef-c5e5d5805653",
   "metadata": {},
   "outputs": [],
   "source": [
    " #3 desde un data frame de pandas\n",
    "## Ejercicio 2 - todo\n",
    "\n",
    "import pandas as pd\n",
    "pandas_df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [2., 3., 4.],\n",
    "    'c': ['string1', 'string2', 'string3'],\n",
    "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
    "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4ec83a-3655-47b1-9aae-16605b90c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>string1</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>string2</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>2000-01-02 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>string3</td>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>2000-01-03 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b        c           d                   e\n",
       "0  1  2.0  string1  2000-01-01 2000-01-01 12:00:00\n",
       "1  2  3.0  string2  2000-02-01 2000-01-02 12:00:00\n",
       "2  3  4.0  string3  2000-03-01 2000-01-03 12:00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#al igual que de un Data set de pandas se puede pasar a un dataset de spark, tambien se puede hacer al contrario\n",
    "df_pandas = df.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bd6fe-7055-455f-a25d-7db373c113ac",
   "metadata": {},
   "source": [
    "## Método 4  desde un rdd\n",
    "\n",
    "la funcion createDataFrme puede recibir un RDD como parámetro, además se le puede indicar el esquema\n",
    "\n",
    "a la hora de indicarle el esquema, se le puede indicar el nombre de las columnas o el nombre y tipo\n",
    "\n",
    "ejemplos:\n",
    "\n",
    "* schema=['a', 'b', 'c', 'd', 'e']\n",
    "* schema='a long, b double, c string, d date, e timestamp'\n",
    "\n",
    "## Ejercicio 3, dado un rdd creado a partir de un array, crear un data set usando como segundo parametro los nombres de la columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5267aae9-6ddb-479f-89e0-8a1e7009847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 desde un RDD\n",
    "\n",
    "# ejercicio 3 - todo\n",
    "myArray= [\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2601d4f-d9e8-48c6-9adb-30b762ba7cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "| _1| _2|     _3|        _4|                 _5|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n",
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: double (nullable = true)\n",
      " |-- _3: string (nullable = true)\n",
      " |-- _4: date (nullable = true)\n",
      " |-- _5: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#desde un rdd usando la funcion toDF()\n",
    "df   = rdd.toDF()\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b288e689-9475-4f93-951b-dc887f5d9394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n",
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#desde un rdd usando la funcion toDF() y pasandole como parametros el nombre de las columnas\n",
    "df   = rdd.toDF(schema=['a', 'b', 'c', 'd', 'e'])\n",
    "df.show()\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e00830-e052-4cbf-b374-54b9993b3db1",
   "metadata": {},
   "source": [
    "## Visualizacion\n",
    "\n",
    "A la hora de mostrar los datos se usa el metodo <b>show()</b>\n",
    "\n",
    "La visualizacion de los resultados con este método no es muy amigable y en caso de tener muchas columnas, puede ser un pcoo lioso.\n",
    "\n",
    "Se puede habilitar <b>spark.sql.repl.eagerEval.enabled </b> para mostar los datos de un modo más amigable \n",
    "\n",
    "* tambien se pueden mostrar las filas de manera vertical, peude venir bien cuando haya muchas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c18820-0bd0-4349-8a17-cf655df3f322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
       "<tr><td>1</td><td>2.0</td><td>string1</td><td>2000-01-01</td><td>2000-01-01 12:00:00</td></tr>\n",
       "<tr><td>2</td><td>3.0</td><td>string2</td><td>2000-02-01</td><td>2000-01-02 12:00:00</td></tr>\n",
       "<tr><td>3</td><td>4.0</td><td>string3</td><td>2000-03-01</td><td>2000-01-03 12:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---+-------+----------+-------------------+\n",
       "|  a|  b|      c|         d|                  e|\n",
       "+---+---+-------+----------+-------------------+\n",
       "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
       "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
       "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
       "+---+---+-------+----------+-------------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ad31cf-58d4-4f07-abbe-f08cc404d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " a   | 1                   \n",
      " b   | 2.0                 \n",
      " c   | string1             \n",
      " d   | 2000-01-01          \n",
      " e   | 2000-01-01 12:00:00 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fddd58f-b471-4c12-ac07-7d5f97767fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columnas del dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08f16ff4-c3dd-4065-84dd-c2e604189d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#esquema del dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6d2e94-a59c-4496-8e75-d2f1a083eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+-------+\n",
      "|summary|  a|  b|      c|\n",
      "+-------+---+---+-------+\n",
      "|  count|  3|  3|      3|\n",
      "|   mean|2.0|3.0|   null|\n",
      "| stddev|1.0|1.0|   null|\n",
      "|    min|  1|2.0|string1|\n",
      "|    max|  3|4.0|string3|\n",
      "+-------+---+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#resumen \"estadístico del dataframe\"\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f915f0f5-a0a0-47bc-b94f-9c1cd8fdafd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mostramos las n primeras filas\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b84b91-1723-4fa0-b801-fd179df9469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mostramos la n ultimas filas\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd9fe2-4186-40df-ad74-f73de3b100df",
   "metadata": {},
   "source": [
    " # Tipos de datos - Data frames\n",
    " \n",
    " Explicacion de los diferentes typos de datos\n",
    " \n",
    " ref: https://spark.apache.org/docs/latest/sql-ref-datatypes.html \n",
    " \n",
    " \n",
    " \n",
    "ByteType: int or long. 1-byte. Range of -128 to 127\n",
    "\n",
    "ShortType: int or long. 2-byte Range of -32768 to 32767\n",
    "\n",
    "IntegerType \n",
    "\n",
    "LongType: 8-byte. +-9223372036854775808\n",
    "\n",
    "FloatType \tfloat. 4-byte single-precision \n",
    "\n",
    "DoubleType \tfloat)\n",
    "\n",
    "DecimalType \tdecimal.Decimal\n",
    "\n",
    "StringType \tstring \n",
    "\n",
    "BinaryType \tbytearray\n",
    "\n",
    "BooleanType \tbool\n",
    "\n",
    "TimestampType \tdatetime.datetime\n",
    "\n",
    "DateType \tdatetime.date\n",
    "\n",
    "ArrayType \tlist, tuple, or array\n",
    "..\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57ee4e-15ca-4805-8ed8-658c3d95c9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

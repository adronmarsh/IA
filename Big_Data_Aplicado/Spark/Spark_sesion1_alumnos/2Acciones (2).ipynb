{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iNyzo2zCh3TY",
   "metadata": {
    "id": "iNyzo2zCh3TY"
   },
   "source": [
    "# Acciones\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions\n",
    "\n",
    "\n",
    "reduce(func) -\tAggregate the elements of the dataset using a function func (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel.\n",
    "\n",
    "collect()\tReturn all the elements of the dataset as an array at the driver program. This is usually useful after a filter or other operation that returns a sufficiently small subset of the data.\n",
    "\n",
    "count()\tReturn the number of elements in the dataset.\n",
    "\n",
    "first()\tReturn the first element of the dataset (similar to take(1)).\n",
    "\n",
    "take(n)\tReturn an array with the first n elements of the dataset.\n",
    "\n",
    "takeSample(withReplacement, num, [seed])\tReturn an array with a random sample of num elements of the dataset, with or without replacement, optionally pre-specifying a random number generator seed.\n",
    "\n",
    "takeOrdered(n, [ordering])\tReturn the first n elements of the RDD using either their natural order or a custom comparator.\n",
    "\n",
    "saveAsTextFile(path)\tWrite the elements of the dataset as a text file (or set of text files) in a given directory in the local filesystem, HDFS or any other Hadoop-supported file system. Spark will call toString on each element to convert it to a line of text in the file.\n",
    "\n",
    "saveAsSequenceFile(path)\n",
    "(Java and Scala)\tWrite the elements of the dataset as a Hadoop SequenceFile in a given path in the local filesystem, HDFS or any other Hadoop-supported file system. This is available on RDDs of key-value pairs that implement Hadoop's Writable interface. In Scala, it is also available on types that are implicitly convertible to Writable (Spark includes conversions for basic types like Int, Double, String, etc).\n",
    "\n",
    "saveAsObjectFile(path)\n",
    "(Java and Scala)\tWrite the elements of the dataset in a simple format using Java serialization, which can then be loaded using SparkContext.objectFile().\n",
    "\n",
    "countByKey()\tOnly available on RDDs of type (K, V). Returns a hashmap of (K, Int) pairs with the count of each key.\n",
    "\n",
    "foreach(func)\tRun a function func on each element of the dataset. This is usually done for side effects such as updating an Accumulator or interacting with external storage systems.\n",
    "\n",
    "Note: modifying variables other than Accumulators outside of the foreach() may result in undefined behavior. See Understanding closures for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbf96cb-277f-4ea9-9e30-78c8bc910425",
   "metadata": {
    "id": "afbf96cb-277f-4ea9-9e30-78c8bc910425",
    "outputId": "552c2975-c409-4b74-9ed3-d9ebec77a602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f47b40ee290>\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inicializamos una aplicacion spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark1\").getOrCreate()\n",
    "print(spark)\n",
    "\n",
    "# creamos un RDD a traves de la funcion parallelize\n",
    "# que recibe como parámetro un array\n",
    "\n",
    "rddNum = spark.sparkContext.parallelize([1,2,3,4,5,6])\n",
    "\n",
    "myarray=[\"haddoop\",\"bigdata\",\"kafka\",\"spark\",\"data\", \"haddoop\",\"kibana\", \"RDD\",\"Mongo\",\"Tableau\",\"nodered\",\"kafka\", \"spark\",\"elastic\",\"bigdata\",\"IESAbastos\",\"IESAbastos\",\"IESAbastos\"]\n",
    "\n",
    "rddString = spark.sparkContext.parallelize(myarray)\n",
    "\n",
    "## con count sacamos el número de elementos\n",
    "print (rddNum.count())\n",
    "\n",
    "# con collect()  obtenemos el contenod del array\n",
    "rddNum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc062a3-7eb4-4379-88ce-0c0c6964dd19",
   "metadata": {
    "id": "5fc062a3-7eb4-4379-88ce-0c0c6964dd19",
    "outputId": "becbe258-981d-433f-f027-20beba2450a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action collect()  obtenemos el contenido del array\n",
    "rddNum.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b4f634-3927-4b1c-9b18-63ae08db1849",
   "metadata": {
    "id": "a3b4f634-3927-4b1c-9b18-63ae08db1849",
    "outputId": "5c15f749-4d6b-4ab3-b220-63025e8a938e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action first()   --> nos devuelve el primer elemento\n",
    "rddNum.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659330ab-8b60-4cbe-bffc-589611439b6e",
   "metadata": {
    "id": "659330ab-8b60-4cbe-bffc-589611439b6e",
    "outputId": "d2561670-d01b-4f4b-a03f-44e3564248f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action count ()  --> nos devuelve el numero de elemento\n",
    "rddNum.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcb3068-4459-40c3-aeb2-6d596172dab6",
   "metadata": {
    "id": "bbcb3068-4459-40c3-aeb2-6d596172dab6",
    "outputId": "0f818271-ecb5-4845-ef46-7aea517af776"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action Reduce --> aplica la misma operacion a todos los elementos del rdd\n",
    "rddNum.reduce(lambda x,y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f184a05e-5616-4d73-8e05-edf117991f46",
   "metadata": {
    "id": "f184a05e-5616-4d73-8e05-edf117991f46",
    "outputId": "7075a24e-69a4-4b60-b360-eb1d32ebfa17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action take --> recupera n elementos\n",
    "rddNum.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf466acb-8cab-4a22-b3c5-cde32b2e887d",
   "metadata": {
    "id": "bf466acb-8cab-4a22-b3c5-cde32b2e887d",
    "outputId": "9ad974ab-9efe-47be-c65b-3efd2a32e8b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action max --> devuelve el máximo\n",
    "rddNum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06112c7f-326f-48dd-bdc0-6f09d9555f2c",
   "metadata": {
    "id": "06112c7f-326f-48dd-bdc0-6f09d9555f2c",
    "outputId": "6525fafa-f315-4c8e-d9b5-792a24b2da98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action min --> devuelve el minimo\n",
    "rddNum.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69083bc-59a4-4153-8127-7f1f67fe9ffd",
   "metadata": {
    "id": "f69083bc-59a4-4153-8127-7f1f67fe9ffd",
    "outputId": "594c5276-fe5d-4f47-a6c4-92920bac7399"
   },
   "outputs": [],
   "source": [
    "# foreach --> recorre todos los elementos\n",
    "rddString.foreach (lambda x: print(\" hola \" +x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a3a706-44fb-4927-abfa-f95a1afd96e9",
   "metadata": {
    "id": "91a3a706-44fb-4927-abfa-f95a1afd96e9",
    "outputId": "f54e85ad-246a-45b5-c777-1f7fb18bb800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RDD', 'elastic', 'bigdata', 'bigdata', 'IESAbastos']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecciona una muestra de elementos\n",
    "rddSample = rddString.takeSample(False,5)\n",
    "rddSample"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

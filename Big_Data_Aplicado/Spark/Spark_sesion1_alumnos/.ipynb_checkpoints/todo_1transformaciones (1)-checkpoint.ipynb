{"cells":[{"cell_type":"markdown","id":"8363fc3c-431b-45e6-8f6d-a949a0a02d4a","metadata":{"id":"8363fc3c-431b-45e6-8f6d-a949a0a02d4a"},"source":["# Libreta con ejercicios de transformacions en sparl\n","\n"]},{"cell_type":"markdown","id":"356b9931-795b-4ed0-811d-71cf870884ab","metadata":{"id":"356b9931-795b-4ed0-811d-71cf870884ab"},"source":["### Referencia a la api de spark\n","\n","Lo primero que tenemos que hacer siempre en una aplicacion spark es crear una sesion de spark y ponerle nombre a la aplicacion,\n","\n","\n","En spark existen 3 maneras de crear un RDD:\n","\n","<B>1)</B> mediante la funcion parallelize sobre una lista\n","\n","myarray = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n","spark.sparkContext.parallelize(myarray)\n","\n","\n","<B>2)</B> Referenciando a un fichero que existe\n","\n","RDD = sc.textFile(\"  / /\")\n","\n","\n","<B>3)</B> Creando un RDD desde otro RDD existente\n","RDD = RDD1.map(lambda x: x +1)\n","\n","\n","\n","\n","https://spark.apache.org/docs/latest/api/python/reference/pyspark.html\n","\n","\n"]},{"cell_type":"code","execution_count":1,"id":"d2caf8bd-12f1-4ebd-90a0-ac3f0171ed25","metadata":{"id":"d2caf8bd-12f1-4ebd-90a0-ac3f0171ed25","outputId":"2580b1c4-6421-4149-c8c7-5979b48b7379"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/01/12 19:12:55 WARN Utils: Your hostname, A208-100 resolves to a loopback address: 127.0.1.1; using 192.168.208.123 instead (on interface eno1)\n","24/01/12 19:12:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/01/12 19:12:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n","24/01/12 19:12:56 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n"]},{"name":"stdout","output_type":"stream","text":["<pyspark.sql.session.SparkSession object at 0x7f4cc8e03280>\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 0:>                                                          (0 + 6) / 6]\r"]},{"name":"stdout","output_type":"stream","text":["6\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["[1, 2, 3, 4, 5, 6]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["#inicializamos una aplicacion spark\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Spark1\").getOrCreate()\n","print(spark)\n","\n","\n","# creamos un RDD a traves de la funcion parallelize\n","# que recibe como parámetro un array\n","\n","rdd = spark.sparkContext.parallelize([1,2,3,4,5,6])\n","\n","## con count sacamos el número de elementos\n","print (rdd.count())\n","\n","# con collect()  obtenemos el contenod del array\n","rdd.collect()\n"]},{"cell_type":"markdown","id":"51c35188-ad67-4f2c-a881-bcb0adcbfc4d","metadata":{"id":"51c35188-ad67-4f2c-a881-bcb0adcbfc4d"},"source":["## 1.1. Creamos una cadena de palabras en python que usaremos para las diferentes transformaciones\n","\n","a) crear un array que contenga entre 10-20 palabras, algunas deben de estar repetidas varias veces.\n","\n","myarray=[\"haddoop\",\"bigdata\",\"kafka\",\"spark\",\"data\", \"haddoop\",\"kibana\", \"RDD\",\"Mongo\",\"Tableau\",\"nodered\",\"kafka\", \"spark\",\"elastic\",\"bigdata\",\"IESAbastos\",\"IESAbastos\",\"IESAbastos\"]\n","\n","b) Una vez tengamos el array hay que crear un RDD por medio de la funcion parallelize.\n","\n","c) sacamos por pantalla el número de elementos del array\n","\n","\n"]},{"cell_type":"code","execution_count":3,"id":"48ad753f-dd39-4bc5-bb6a-d75c9803173b","metadata":{"id":"48ad753f-dd39-4bc5-bb6a-d75c9803173b"},"outputs":[{"name":"stdout","output_type":"stream","text":["18\n"]}],"source":["myarray=[\"haddoop\",\"bigdata\",\"kafka\",\"spark\",\"data\", \"haddoop\",\"kibana\", \"RDD\",\"Mongo\",\"Tableau\",\"nodered\",\"kafka\", \"spark\",\"elastic\",\"bigdata\",\"IESAbastos\",\"IESAbastos\",\"IESAbastos\"]\n","\n","myRDD = spark.sparkContext.parallelize(myarray)\n","\n","print(myRDD.count())"]},{"cell_type":"markdown","id":"59438448-37d6-4f08-b56f-ce73e39890a5","metadata":{"id":"59438448-37d6-4f08-b56f-ce73e39890a5"},"source":["## 1.2 Tansformaciones MAP\n","\n","Gracias a la funcion map podemos transformar de manera simple todos los elementos de un rdd.\n","Para las transformaciones en pyspark se suele usar una funcion lambda:\n","             (lamba   x: \"transformacion a aplicar\")\n","\n","REF- lambda: https://www.freecodecamp.org/espanol/news/expresiones-lambda-en-python/\n","- https://docs.python.org/es/3/reference/expressions.html#lambda\n","\n","\n","\n","\n","<b>ejercicio 1</b> Transformar todos los elementos a mayuscula\n","\n","\n"]},{"cell_type":"code","execution_count":4,"id":"17acc0d4-6a7f-4ba0-8dee-cfea155b7b7a","metadata":{"id":"17acc0d4-6a7f-4ba0-8dee-cfea155b7b7a"},"outputs":[],"source":["myRDDMayusculas = myRDD.map(lambda x: x.upper())"]},{"cell_type":"markdown","id":"0b763e39-5510-406e-8540-3794ce5c8659","metadata":{"id":"0b763e39-5510-406e-8540-3794ce5c8659"},"source":["## 1.3  Transformacion filter\n","    \n","mediante la transformacion filter podemos filtrar los elemento sde la cadana en base a una condició (\"que empieze por\", \"que contenga\", que acabe)\n","    \n","\n","\n","Ejercicio2:\n","- realizar un RDD que contenga todos los elementos que empiecen por un string \"B\".\n","-\n","\n","- realizar un RDD que contenga todos los elementos que terminen por string \"A\"\n","\n","\n","\n","    "]},{"cell_type":"code","execution_count":17,"id":"f2b7b710-707e-4a21-90b6-56cc8b958a00","metadata":{"id":"f2b7b710-707e-4a21-90b6-56cc8b958a00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Empiezan con \"B\": ['BIGDATA', 'BIGDATA']\n","Terminan con \"A\": ['BIGDATA', 'KAFKA', 'DATA', 'KIBANA', 'KAFKA', 'BIGDATA']\n"]}],"source":["\n","#Ejercicio 2\n","ConB = myRDDMayusculas.filter(lambda x: x.startswith(\"B\"))\n","print('Empiezan con \"B\":', ConB.collect())\n","finA = myRDDMayusculas.filter(lambda x:x.endswith(\"A\"))\n","print('Terminan con \"A\":', finA.collect())\n"]},{"cell_type":"markdown","id":"012e958e-f600-4f05-97a2-096f1ce9c026","metadata":{"id":"012e958e-f600-4f05-97a2-096f1ce9c026"},"source":["## 1.4 transformacion flatmap\n","La transformacion flatMap , es parecida a la map, pero en este caso mapea y aplana.\n","Por ejemplo. Con flatmap, una linea con varias palabras, se podria mapear en varias listas. Es decir que de un elemento del RDD puede crear más de un elemento en el rdd nuevo.\n","\n","Dado el siguiente array de tres elementos\n","[\"Curso Especialista Inteligencia Artificial\",\"Desarrollo aplicaciones web\",\"Instituto IESAbastos es el mejor\" ]\n","\n","Si usamos map tendríamos 1 arrays con 3 elementos. Y dentro de cada array, de manera anidada tendriamos otro array con las palabras.\n","\n","[['Curso', 'Especialista', 'Inteligencia', 'Artificial'],\n"," ['Desarrollo', 'aplicaciones', 'web'],\n"," ['Instituto', 'IESAbastos', 'es', 'el', 'mejor']]\n","\n","Si usamos flatmap en vez de tener un array con 3 elementos, tendriamos un array con tantos elementos como palabras tenemos.\n","\n","\n","\n","**Ejercicio 3**, dadas las tres frases siguientes\n","\n","myLines = [\"Curso Especialista Inteligencia Artificial\",\"Desarrollo aplicaciones web\",\"Instituto IESAbastos es el mejor\" ]\n","\n","3.1 - Contruir un array que separe las frases en palabras usando map\n","\n","3.2 - construir un rdd que contenga tantas entradas como palabras tenemos en el array.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"03c36bae-7f15-4780-b61a-9cb44a50a4e5","metadata":{"id":"03c36bae-7f15-4780-b61a-9cb44a50a4e5"},"outputs":[],"source":["#ejercicio 3.1\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6bd2224f-177f-4550-b810-a8b482947558","metadata":{"id":"6bd2224f-177f-4550-b810-a8b482947558"},"outputs":[],"source":["#ejercicio 3.2\n","\n"]},{"cell_type":"markdown","id":"5c227546-c919-4586-822b-c32eac9b66cf","metadata":{"id":"5c227546-c919-4586-822b-c32eac9b66cf"},"source":["## 1.5.  Transformacion de Unión\n","\n","A través de esta transformación podemos unir dos RDDS\n","\n","**Ejercicio 4**: Coger dos de los RDDs anteriores y unirlos\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"56fc7c4c-c426-4adc-802f-20f7a99e14f8","metadata":{"id":"56fc7c4c-c426-4adc-802f-20f7a99e14f8"},"outputs":[],"source":["#ejercio 4\n","\n","\n"]},{"cell_type":"markdown","id":"83148bbd-4922-4360-9108-dde5749545e7","metadata":{"id":"83148bbd-4922-4360-9108-dde5749545e7"},"source":["## 1.6.  Transformacion Distinct\n","\n","Elimina todos los elementos repetidos de un RDD\n","\n","**Ejercicio 5**: Coger el RDD anterios (si tiene palabras repetidas) y aplicarle la transformacion distinct.\n","\n","Nota: En caso de no tener palabras repetidas usar el siguiente array\n","myarray = [\"haddoop\",\"bigdata\",\"haddoop\",\"spark\",\"data\", \"haddoop\",\"kibana\", \"RDD\", \"spark\",\"elastic\",\"bigdata\",\"IESAbastos\",\"IESAbastos\",\"IESAbastos\" ]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e686d26c-ab49-4a6a-91bb-f3c002d4c05b","metadata":{"id":"e686d26c-ab49-4a6a-91bb-f3c002d4c05b"},"outputs":[],"source":["#Ejercicio 5\n","\n"]},{"cell_type":"markdown","id":"1b3895eb-1d86-4e51-9565-e1fcf69aac11","metadata":{"id":"1b3895eb-1d86-4e51-9565-e1fcf69aac11"},"source":["## 1.7.  Transformacion groupByKey y reduceByKey\n","\n","\n","groupBykey y reducebyKey permiten agrupar /o reducir el numero de elementos de una lista en funcion de la clave.  \n","Para ello:\n","- primero se tiene que crear una tupla clave y numero de veces que aparece la palabra.\n","\n","               (lambda x:  (x,1))\n","               \n","- una vez creada la tupla se aplica reduceByKey usando el operador add, lo que nos permite sumar el numero de veces que apacera un elemento\n","\n","**Ejercicio 6**: Contar el número de veces que aparecen todas las palabras del siguiente array\n","\n","myarray = [\"haddoop\",\"bigdata\",\"haddoop\",\"spark\",\"data\", \"haddoop\",\"kibana\", \"RDD\", \"spark\",\"elastic\",\"bigdata\",\"IESAbastos\",\"IESAbastos\",\"IESAbastos\" ]\n"]},{"cell_type":"code","execution_count":null,"id":"f332455d-1c67-474e-9c74-2c074c33cf3b","metadata":{"id":"f332455d-1c67-474e-9c74-2c074c33cf3b"},"outputs":[],"source":["#Ejercicio 6\n","from operator import add   ## dejar esta linea\n","\n","\n"]},{"cell_type":"markdown","id":"6f071468-ebcc-4058-83b4-42bf0fd6f4de","metadata":{"id":"6f071468-ebcc-4058-83b4-42bf0fd6f4de"},"source":["# 1.8.  Transformacion ordenacion \"sortByKey\"\n","\n","Dada una lista de pares (clave ,valor), con el método sortbyKey podemos ordenar los valores por la clave, tanto de manera ascendente como descendente\n","\n","True --> ascendente\n","False--> descendente\n","\n","**Ejercicio 7**: Ordena los valores de la lista anterior por la clave  de manera ascendente"]},{"cell_type":"code","execution_count":null,"id":"1ff5e251-a751-4bba-93be-c801df37ee65","metadata":{"id":"1ff5e251-a751-4bba-93be-c801df37ee65"},"outputs":[],"source":["#ejercio7\n","\n","\n"]},{"cell_type":"markdown","id":"068ed420-dade-48a3-9b20-2b5f10b698b5","metadata":{"id":"068ed420-dade-48a3-9b20-2b5f10b698b5"},"source":["<b>Ejercicio</b> 8  ordena los valores de la lista 6 por el valor en vez de por la clave"]},{"cell_type":"code","execution_count":null,"id":"b4e4a94c-a32f-45ef-b3aa-82d7a4b40312","metadata":{"id":"b4e4a94c-a32f-45ef-b3aa-82d7a4b40312"},"outputs":[],"source":["#ejercio 8\n"]},{"cell_type":"markdown","id":"fe637772-e1b5-4eb9-9ec4-6710d07e44eb","metadata":{"id":"fe637772-e1b5-4eb9-9ec4-6710d07e44eb"},"source":["Tambien es comun filtar las palabras que tengan un minimo numero de caracteres\n","\n","<b>Ejercicio 9</b> Dado un rdd de palabras filtrar las palabras que tienen una logitud mayor a x caracteres"]},{"cell_type":"code","execution_count":null,"id":"60886eca-d083-46db-addf-5c3a326741fd","metadata":{"id":"60886eca-d083-46db-addf-5c3a326741fd"},"outputs":[],"source":["#ejercio 9\n","\n","\n"]},{"cell_type":"markdown","id":"7a4d776b-9733-43a3-84ed-d1f117ffc7cf","metadata":{"id":"7a4d776b-9733-43a3-84ed-d1f117ffc7cf"},"source":["\n","<b>Ejercicio 9</b> Dado el siguiente array\n","\n","myarraylineas = [\"haddoop bigdata haddoop spark tableau nodered\",\"data nodered  haddoop kibana RDD\", \"spark  elastic  bigdata IESAbastos IESAbastos IESAbastos\" ]\n","\n","Se pide mostrar las palablas de mas de 6 carácteres que aparecen en el array ordenadas de manera descendiente por el numero de veces que aparecen.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"98592279-7266-4b41-bb10-33a0ee6b8fc3","metadata":{"id":"98592279-7266-4b41-bb10-33a0ee6b8fc3"},"outputs":[],"source":["\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6548d808-bc28-48b3-bfab-5d1d90209f7e","metadata":{"id":"6548d808-bc28-48b3-bfab-5d1d90209f7e"},"outputs":[],"source":["Ejercicio 10.\n","\n","Repetir el ejercicio, pero esta vez usad como entrada de datos el fichero txt que contiene la descripcion del quijote.\n","\n","Sacar por pantalla las 10 palabras de entre 6-10 carácteres que más se repitan en el libro\n","\n"]},{"cell_type":"code","execution_count":null,"id":"698546a0-7dfa-44b6-b0f7-6ec20bf7fd3c","metadata":{"id":"698546a0-7dfa-44b6-b0f7-6ec20bf7fd3c"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}

{"cells":[{"cell_type":"markdown","metadata":{"id":"zfkgslI1xiIM"},"source":["# Lab 3: Experimentación de hiperparámetros.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dgOn5xMhxiIO"},"source":["El objetivo de este laboratorio es experimentar con los conceptos teoricos vistos en clase. Se propone seguir la estructura de experimentos del documento. Como hemos visto durante el tema es muy importante vuestra conclusión después del experimento.\n","\n","Para evaluar con cual nos quedamos después de cada experimento vamos a quedarnos con el que tenga mejor Accuracy en los datos de validación.\n","\n","El dataset a utilizar consiste en imágenes de personajes de los Simpsons extraídas directamente de capítulos de la serie. Este dataset ha sido recopilado por [Alexandre Attia](http://www.alexattia.fr/) y es más complejo que el dataset de Fashion MNIST que hemos utilizado hasta ahora. Aparte de tener más clases (vamos a utilizar los 18 personajes con más imágenes), los personajes pueden aparecer en distintas poses, en distintas posiciones de la imagen o con otros personajes en pantalla (si bien el personaje a clasificar siempre aparece en la posición predominante).\n","\n","El dataset de training puede ser descargado desde aquí:\n","\n","[Training data](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60) (~500MB)\n","\n","Por otro lado, el dataset de test puede ser descargado de aquí:\n","\n","[Test data](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8) (~10MB)\n","\n","Antes de empezar la práctica, se recomienda descargar las imágenes y echarlas un vistazo."]},{"cell_type":"markdown","metadata":{"id":"QI274F8LQC59"},"source":["## Carga de los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7tKOZ9BFfki"},"outputs":[],"source":["import cv2\n","import os\n","import numpy as np \n","import keras\n","import matplotlib.pyplot as plt\n","import glob\n","\n","\n","# Primero, bajamos los datos de entrenamiento\n","keras.utils.get_file(fname=\"simpsons_train.tar.gz\", \n","                     origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60\")\n","\n","# Descomprimimos el archivo\n","!tar -xzf /root/.keras/datasets/simpsons_train.tar.gz -C /root/.keras/datasets\n","\n","# Hacemos lo mismo con los datos de test\n","keras.utils.get_file(fname=\"simpsons_test.tar.gz\", \n","                     origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8\")\n","!tar -xzf /root/.keras/datasets/simpsons_test.tar.gz -C /root/.keras/datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMFhe3COFwSD"},"outputs":[],"source":["# Esta variable contiene un mapeo de número de clase a personaje.\n","# Utilizamos sólo los 18 personajes del dataset que tienen más imágenes.\n","MAP_CHARACTERS = {\n","    0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson',\n","    3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n","    7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson', \n","    11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak', \n","    14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'\n","}\n","\n","# Vamos a standarizar todas las imágenes a tamaño 64x64\n","IMG_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bJ0NsbCbupF"},"outputs":[],"source":["def load_train_set(dirname, map_characters, verbose=True):\n","    \"\"\"Esta función carga los datos de training en imágenes.\n","    \n","    Como las imágenes tienen tamaños distintas, utilizamos la librería opencv\n","    para hacer un resize y adaptarlas todas a tamaño IMG_SIZE x IMG_SIZE.\n","    \n","    Args:\n","        dirname: directorio completo del que leer los datos\n","        map_characters: variable de mapeo entre labels y personajes\n","        verbose: si es True, muestra información de las imágenes cargadas\n","     \n","    Returns:\n","        X, y: X es un array con todas las imágenes cargadas con tamaño\n","                IMG_SIZE x IMG_SIZE\n","              y es un array con las labels de correspondientes a cada imagen\n","    \"\"\"\n","    X_train = []\n","    y_train = []\n","    for label, character in map_characters.items():        \n","        files = os.listdir(os.path.join(dirname, character))\n","        images = [file for file in files if file.endswith(\"jpg\")]\n","        if verbose:\n","          print(\"Leyendo {} imágenes encontradas de {}\".format(len(images), character))\n","        for image_name in images:\n","            image = cv2.imread(os.path.join(dirname, character, image_name))\n","            X_train.append(cv2.resize(image,(IMG_SIZE, IMG_SIZE)))\n","            y_train.append(label)\n","    return np.array(X_train), np.array(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NslxhnnDK6uA"},"outputs":[],"source":["def load_test_set(dirname, map_characters, verbose=True):\n","    \"\"\"Esta función funciona de manera equivalente a la función load_train_set\n","    pero cargando los datos de test.\"\"\"\n","    X_test = []\n","    y_test = []\n","    reverse_dict = {v: k for k, v in map_characters.items()}\n","    for filename in glob.glob(dirname + '/*.*'):\n","        char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n","        if char_name in reverse_dict:\n","            image = cv2.imread(filename)\n","            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n","            X_test.append(image)\n","            y_test.append(reverse_dict[char_name])\n","    if verbose:\n","        print(\"Leídas {} imágenes de test\".format(len(X_test)))\n","    return np.array(X_test), np.array(y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVWqKxFcbwTu"},"outputs":[],"source":["# Cargamos los datos. Si no estás trabajando en colab, cambia los paths por\n","# los de los ficheros donde hayas descargado los datos.\n","DATASET_TRAIN_PATH_COLAB = \"/root/.keras/datasets/simpsons\"\n","DATASET_TEST_PATH_COLAB = \"/root/.keras/datasets/simpsons_testset\"\n","\n","x_train, y_train = load_train_set(DATASET_TRAIN_PATH_COLAB, MAP_CHARACTERS)\n","x_test, y_test = load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GY4vTFyfffv"},"outputs":[],"source":["# Vamos a barajar aleatoriamente los datos. Esto es importante ya que si no\n","# lo hacemos y, por ejemplo, cogemos el 20% de los datos finales como validation\n","# set, estaremos utilizando solo un pequeño número de personajes, ya que\n","# las imágenes se leen secuencialmente personaje a personaje.\n","perm = np.random.permutation(len(x_train))\n","x_train, y_train = x_train[perm], y_train[perm]"]},{"cell_type":"markdown","source":["## Herramientas de visualización de resultados"],"metadata":{"id":"ME2AdY059Jdc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_m-XlL9XbHMh"},"outputs":[],"source":["# Definición de funciones que permitirán la visualización de las graficas de entrenamiento\n","def plot_acc(history, title=\"Model Accuracy\"):\n","    \"\"\"Imprime una gráfica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title(title)\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n","    plt.show()\n","    \n","def plot_loss(history, title=\"Model Loss\"):\n","    \"\"\"Imprime una gráfica mostrando la pérdida por epoch obtenida en un entrenamiento\"\"\"\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title(title)\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Entrenamiento', 'Validación'], loc='upper right')\n","    plt.show()\n","    \n","def plot_compare_losses(history1, history2, name1=\"Red 1\",\n","                        name2=\"Red 2\", title=\"Graph title\"):\n","    \"\"\"Compara losses de dos entrenamientos con nombres name1 y name2\"\"\"\n","    plt.plot(history1.history['loss'], color=\"green\")\n","    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n","    plt.plot(history2.history['loss'], color=\"blue\")\n","    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n","    plt.title(title)\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Entrenamiento ' + name1, 'Validación ' + name1, \n","                'Entrenamiento ' + name2, 'Validación ' + name2],\n","               loc='upper right')\n","    plt.show()\n","    \n","def plot_compare_accs(history1, history2, name1=\"Red 1\",\n","                      name2=\"Red 2\", title=\"Graph title\"):\n","    \"\"\"Compara accuracies de dos entrenamientos con nombres name1 y name2\"\"\"\n","    plt.plot(history1.history['accuracy'], color=\"green\")\n","    plt.plot(history1.history['val_accuracy'], 'r--', color=\"green\")\n","    plt.plot(history2.history['accuracy'], color=\"blue\")\n","    plt.plot(history2.history['val_accuracy'], 'r--', color=\"blue\")\n","    plt.title(title)\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train ' + name1, 'Val ' + name1, \n","                'Train ' + name2, 'Val ' + name2], \n","               loc='lower right')\n","    plt.show()\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"pBbmz9DMhVhc"},"source":["## Cosas a tener en cuenta:\n","\n","A continuación se detallan una serie de aspectos orientativos que podrían ser analizados en vuestro informe\n","\n","*   Realizar un análisis de los datos a utilizar.\n","* Recuerda partir los datos en training/validation para tener una buena estimación de los valores que nuestro modelo tendrá en los datos de test, así como comprobar que no estamos cayendo en overfitting. Una posible partición puede ser 80 / 20.\n","* Las imágenes **no están normalizadas**. Hay que normalizarlas como hemos hecho en trabajos anteriores.\n","* El test set del problema tiene imágenes un poco más \"fáciles\", por lo que es posible encontrarse con métricas en el test set bastante mejores que en el training set.\n","* Un error común en Keras es no instanciar un nuevo modelo cada vez que hacemos un nuevo entrenamiento. Al hacer\n","\n","      *model = Sequential()*\n","      *model.add(lo que sea)  # Definición del modelo*\n","      *model.fit()*\n","\n","    Si queremos entrenar un nuevo modelo o el mismo modelo otra vez, es necesario volver a inicializar el modelo con model = Sequential().\n","    Si olvidamos este paso y volvemos a hacer fit(), el modelo seguirá entrenando por donde se quedó en el último fit().\n","* Se recomienda construir una tabla con el mejor valor del acurracy y función de validación .\n","* Vamos a utilizar la misma arquitectura de red neuronal para todos los experimentos, que mostramos a continuación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5MOXB43HNFQf"},"outputs":[],"source":["from keras import layers\n","from keras import models\n","from keras.optimizers import Adamax, RMSprop, SGD\n","from keras.callbacks import EarlyStopping\n","\n","\n","# Definición y construcción del modelo 1\n","model = models.Sequential()\n","model.add(layers.Conv2D(64,(2,2), activation='relu', input_shape=(64, 64, 3), padding='same', name='Convolutiva-1'))\n","model.add(layers.MaxPooling2D(pool_size=(2,2), name='MaxPooling-1'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu', name='Hidden-Layer-1'))\n","model.add(layers.Dense(64, activation='relu', name='Hidden-Layer-2'))\n","model.add(layers.Dense(18, activation='softmax', name='Output-Layer'))\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"j7AhTe2YNjpZ"},"source":["## Realización de los experimentos"]},{"cell_type":"markdown","source":["### Experimento 1: Visualización y preparación del dataset"],"metadata":{"id":"O-32xjrQ_YHu"}},{"cell_type":"markdown","source":["  * Visualizar algunas imagenes aleatoriamente. \n","  * Comprobar el número de imagenes y formato.\n","  * Normalizar.\n","  * Cualquier otra acción que consideres oportuna que enriquezca el experimento."],"metadata":{"id":"Z0eb8sE7_oVT"}},{"cell_type":"markdown","metadata":{"id":"YrU9GHKjNLuc"},"source":["Primeramente vamos a visualizar aleatoriamente algunas imagenes del dataset de training junto con su etiqueta."]},{"cell_type":"markdown","source":["### Experimento 2:  Relu vs Tangente hiperbólica"],"metadata":{"id":"Ap8ZdxBTAzBM"}},{"cell_type":"markdown","source":["Para la realización de este experimento tiene que utilizar los siguientes hiperparámetros:\n","\n","\n","*   Optimizer: SGD\n","*   Loss: sparse_categorical_crossentropy\n","*   Metrics: accuracy\n","*   EarlyStopping\n","      *   monitor=val_loss\n","      *   patience = 2\n","      *   verbose=1\n","*   Batch_size: 32\n","\n","\n"],"metadata":{"id":"LxqTInNoBHrt"}},{"cell_type":"markdown","source":["Construcción del modelo Relu."],"metadata":{"id":"oiT3h4aaC-j3"}},{"cell_type":"markdown","source":["### Experimento 3: Zero vs Glorot uniform\n","\n"],"metadata":{"id":"t4f8HBfaF0m9"}},{"cell_type":"markdown","source":["### Experimento 4 - Aleatoria Normal vs Glorot uniform  \n"],"metadata":{"id":"FM9AyoSvKP0P"}},{"cell_type":"markdown","source":["###Experimento 5 - SGD vs RMSprop\n","\n","\n"],"metadata":{"id":"422esP0qLhXt"}},{"cell_type":"markdown","source":["###Experimento 6: SGD vs Adamax"],"metadata":{"id":"pm9ONXJlODvI"}},{"cell_type":"markdown","source":["Probar con learning_rate=0.002, beta_1=0.9, beta_2=0.999"],"metadata":{"id":"q00aYK83OQU_"}},{"cell_type":"markdown","source":["###Experimento 7: Aumento batch size 512"],"metadata":{"id":"E_fCvpGdPEJf"}},{"cell_type":"markdown","source":["### Experimento 8 - Aplicar BatchNormalization"],"metadata":{"id":"6vL4A74WW9QG"}},{"cell_type":"markdown","source":["### Experimento 9 - Aumentar el número de parámentros por capa"],"metadata":{"id":"fRT3nIIaZgcp"}},{"cell_type":"markdown","source":["Aumentar de la siguiente manera:\n","\n","*   512 a la Conv2D\n","*   512 a la primera Dense\n","*   256 a la segunda Dense\n","\n"],"metadata":{"id":"A6bMeCgX9GMt"}},{"cell_type":"markdown","source":["### Experimento 10 - Aplicar Dropout 0.2"],"metadata":{"id":"YOAPpVt8ZU9w"}},{"cell_type":"markdown","source":["###Anexos"],"metadata":{"id":"Egp7qVnScMP3"}},{"cell_type":"markdown","source":["Si os encontrais alguna anomalia mientras realizais el laboratorio, describirla en este punto, motivos del problema y solución.\n"],"metadata":{"id":"RWJV0-pVeN8J"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}